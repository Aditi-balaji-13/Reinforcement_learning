"""
DO NOT EDIT THIS FILE. ANY CHANGES WILL BE OVERWRITTEN
THIS FILE USES THE FUNCTIONS IMPLEMENTED IN agent.py TO EVALUATE YOUR AGENTS
"""

import os
import aicrowd_gym
import gym_bellman
import numpy as np
from tqdm import trange
import gym
from agent import Agent


def train(agent, env):
    obs = env.reset()
    action = agent.register_reset_train(obs)
    done = False
    while not done:
        obs, reward, done, info = env.step(action)
        action = agent.compute_action_train(obs, reward, done, info)


def evaluate(agent, env):
    rewards = 0
    obs = env.reset()
    action = agent.register_reset_test(obs)
    done = False
    while not done:
        obs, reward, done, info = env.step(action)
        action = agent.compute_action_test(obs, reward, done, info)
        rewards += reward

    return rewards


if __name__ == "__main__":
    ENV_NAME = os.getenv("ENV_NAME", "acrobot")

    N_TRAIN_EPISODES = {"acrobot": 3000, "taxi": 1500, "bellman": 1000}

    N_EVAL_EPISODES = 100

    if ENV_NAME == "acrobot":
        env = aicrowd_gym.make("Acrobot-v1")
    elif ENV_NAME == "taxi":
        env = aicrowd_gym.make("Taxi-v3")
    elif ENV_NAME == "bellman":
        env = aicrowd_gym.make("bellman-v0")

    agent = Agent(ENV_NAME)

    for i in trange(N_TRAIN_EPISODES[ENV_NAME], desc="Training"):
        train(agent, env)

    rewards = []
    for i in trange(N_EVAL_EPISODES, desc="Evaluating"):
        rewards.append(evaluate(agent, env))

    print(f"Mean reward on your agent for {ENV_NAME} is {np.mean(rewards)}")
