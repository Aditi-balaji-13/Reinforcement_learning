"""
DO NOT EDIT THIS FILE. ANY CHANGES WILL BE OVERWRITTEN
THIS FILE USES THE FUNCTIONS IMPLEMENTED IN agent.py TO EVALUATE YOUR AGENTS
"""

import os
import gym
import numpy as np

from agent import Agent

def train(agent, env,max_time_steps):
    pass


def evaluate(agent, env):
    rewards = 0 
    obs = env.reset()
    action = agent.register_reset()
    done = False
    while not done:
        obs, reward, done, info = env.step(action)
        action = agent.compute_action(obs, reward, done, info)
        rewards += reward
    return reward

if __name__== "main":
    agent = Agent()
    ENV_NAME = os.getenv("ENV_NAME","acrobot")

    max_train_steps = {
        "acrobat": 10000,
        "taxi": 10000,
        "bellman": 1000
    }

    N_EVAL_EPISODES = 100

    if ENV_NAME == "acrobot":
        env = gym.make("Acrobot-v1")
    elif ENV_NAME == "taxi":
        env = gym.make("Taxi-v3")
    elif ENV_NAME == "bellman":
        env = gym.make("BellmansDP-v0")

    train(agent ,env,max_train_steps[ENV_NAME])

    rewards = []
    for i in range(N_EVAL_EPISODES):
        rewards.append(evaluate(agent, env))

    print("Mean reward on your agent for {env} is {np.mean(rewards)}")

